{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>HOMA</th>\n",
       "      <th>Leptin</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>Resistin</th>\n",
       "      <th>MCP.1</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>70</td>\n",
       "      <td>2.707</td>\n",
       "      <td>0.467409</td>\n",
       "      <td>8.8071</td>\n",
       "      <td>9.702400</td>\n",
       "      <td>7.99585</td>\n",
       "      <td>417.114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>20.690495</td>\n",
       "      <td>92</td>\n",
       "      <td>3.115</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>8.8438</td>\n",
       "      <td>5.429285</td>\n",
       "      <td>4.06405</td>\n",
       "      <td>468.786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>23.124670</td>\n",
       "      <td>91</td>\n",
       "      <td>4.498</td>\n",
       "      <td>1.009651</td>\n",
       "      <td>17.9393</td>\n",
       "      <td>22.432040</td>\n",
       "      <td>9.27715</td>\n",
       "      <td>554.697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>21.367521</td>\n",
       "      <td>77</td>\n",
       "      <td>3.226</td>\n",
       "      <td>0.612725</td>\n",
       "      <td>9.8827</td>\n",
       "      <td>7.169560</td>\n",
       "      <td>12.76600</td>\n",
       "      <td>928.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>92</td>\n",
       "      <td>3.549</td>\n",
       "      <td>0.805386</td>\n",
       "      <td>6.6994</td>\n",
       "      <td>4.819240</td>\n",
       "      <td>10.57635</td>\n",
       "      <td>773.920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age        BMI  Glucose  Insulin      HOMA   Leptin  Adiponectin  Resistin  \\\n",
       "0   48  23.500000       70    2.707  0.467409   8.8071     9.702400   7.99585   \n",
       "1   83  20.690495       92    3.115  0.706897   8.8438     5.429285   4.06405   \n",
       "2   82  23.124670       91    4.498  1.009651  17.9393    22.432040   9.27715   \n",
       "3   68  21.367521       77    3.226  0.612725   9.8827     7.169560  12.76600   \n",
       "4   86  21.111111       92    3.549  0.805386   6.6994     4.819240  10.57635   \n",
       "\n",
       "     MCP.1  Classification  \n",
       "0  417.114               1  \n",
       "1  468.786               1  \n",
       "2  554.697               1  \n",
       "3  928.220               1  \n",
       "4  773.920               1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Summary:\n",
      "              Age         BMI     Glucose     Insulin        HOMA      Leptin  \\\n",
      "count  116.000000  116.000000  116.000000  116.000000  116.000000  116.000000   \n",
      "mean    57.301724   27.582111   97.793103   10.012086    2.694988   26.615080   \n",
      "std     16.112766    5.020136   22.525162   10.067768    3.642043   19.183294   \n",
      "min     24.000000   18.370000   60.000000    2.432000    0.467409    4.311000   \n",
      "25%     45.000000   22.973205   85.750000    4.359250    0.917966   12.313675   \n",
      "50%     56.000000   27.662416   92.000000    5.924500    1.380939   20.271000   \n",
      "75%     71.000000   31.241442  102.000000   11.189250    2.857787   37.378300   \n",
      "max     89.000000   38.578759  201.000000   58.460000   25.050342   90.280000   \n",
      "\n",
      "       Adiponectin    Resistin        MCP.1  Classification  \n",
      "count   116.000000  116.000000   116.000000      116.000000  \n",
      "mean     10.180874   14.725966   534.647000        1.551724  \n",
      "std       6.843341   12.390646   345.912663        0.499475  \n",
      "min       1.656020    3.210000    45.843000        1.000000  \n",
      "25%       5.474283    6.881763   269.978250        1.000000  \n",
      "50%       8.352692   10.827740   471.322500        2.000000  \n",
      "75%      11.815970   17.755207   700.085000        2.000000  \n",
      "max      38.040000   82.100000  1698.440000        2.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dataR2.csv\")\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nDataset Summary:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import RFE   \n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***NAIVE APPROACH WITH SOME PARAMETERS***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Algorithm   C.C.I.%  Precision    Recall  F-measure\n",
      "0  Baseline Classifier  0.551724   0.304400  0.551724   0.392337\n",
      "1  Logistic Regression  0.687879   0.721989  0.687879   0.665287\n",
      "2        Decision Tree  0.678788   0.705592  0.705303   0.680622\n",
      "3           k-NN (k=5)  0.650000   0.639278  0.650000   0.629348\n",
      "4       Neural Network  0.694697   0.695891  0.685606   0.671177\n"
     ]
    }
   ],
   "source": [
    "# Define features and target variable\n",
    "X = df.drop(columns=['Classification'])  # Assuming 'Classification' is the target column\n",
    "y = df['Classification']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"k-NN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Neural Network\": MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1000)\n",
    "}\n",
    "\n",
    "# Perform 10-fold cross-validation and collect results\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    accuracy = np.mean(cross_val_score(model, X_scaled, y, cv=10, scoring='accuracy'))\n",
    "    precision = np.mean(cross_val_score(model, X_scaled, y, cv=10, scoring='precision_weighted'))\n",
    "    recall = np.mean(cross_val_score(model, X_scaled, y, cv=10, scoring='recall_weighted'))\n",
    "    f1 = np.mean(cross_val_score(model, X_scaled, y, cv=10, scoring='f1_weighted'))\n",
    "    results.append([name, accuracy, precision, recall, f1])\n",
    "\n",
    "# Baseline classifier (predicts majority class always)\n",
    "majority_class = y.mode()[0]\n",
    "baseline_preds = np.full(y.shape, majority_class)\n",
    "baseline_acc = accuracy_score(y, baseline_preds)\n",
    "baseline_prec = precision_score(y, baseline_preds, average='weighted', zero_division=0)\n",
    "baseline_recall = recall_score(y, baseline_preds, average='weighted', zero_division=0)\n",
    "baseline_f1 = f1_score(y, baseline_preds, average='weighted', zero_division=0)\n",
    "results.insert(0, [\"Baseline Classifier\", baseline_acc, baseline_prec, baseline_recall, baseline_f1])\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results, columns=[\"Algorithm\", \"C.C.I.%\", \"Precision\", \"Recall\", \"F-measure\"])\n",
    "\n",
    "# Display the table\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***LOGISTIC REGRESSION***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters based on Precision:\n",
      "C                      10.0\n",
      "Solver            liblinear\n",
      "Max Iterations         5000\n",
      "C.C.I.%            0.696212\n",
      "Precision          0.724716\n",
      "Recall             0.696212\n",
      "F-measure          0.678207\n",
      "Name: 32, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for Logistic Regression\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 50, 100, 200],  # Expanded range\n",
    "    'solver': ['liblinear', 'newton-cg'],  # Additional solvers\n",
    "    'max_iter': [5000, 10000, 20000, 50000]  # Increased iterations\n",
    "}\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv=10, scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'], refit=False, n_jobs=-1)\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Collect all results\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results = cv_results[['param_C', 'param_solver', 'param_max_iter', 'mean_test_accuracy', 'mean_test_precision_weighted', 'mean_test_recall_weighted', 'mean_test_f1_weighted']]\n",
    "cv_results.columns = [\"C\", \"Solver\", \"Max Iterations\", \"C.C.I.%\", \"Precision\", \"Recall\", \"F-measure\"]\n",
    "\n",
    "\n",
    "# Find and print the best parameters\n",
    "best_params_logreg = cv_results.loc[cv_results['Precision'].idxmax()]\n",
    "print(\"Best Parameters based on Precision:\")\n",
    "print(best_params_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***DECISION TREE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters based on Precision:\n",
      "Criterion             entropy\n",
      "Max Depth                  30\n",
      "Min Samples Split           5\n",
      "Min Samples Leaf            5\n",
      "C.C.I.%              0.759848\n",
      "Precision            0.809842\n",
      "Recall               0.759848\n",
      "F-measure            0.750836\n",
      "Name: 61, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for Decision Tree\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],  # Different split criteria\n",
    "    'max_depth': [10, 20, 30, 50],  # Varying tree depths\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples needed to split a node\n",
    "    'min_samples_leaf': [1, 2, 5]  # Minimum samples needed at a leaf node\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=10, scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'], refit=False, n_jobs=-1)\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Collect all results\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results = cv_results[['param_criterion', 'param_max_depth', 'param_min_samples_split', 'param_min_samples_leaf', 'mean_test_accuracy', 'mean_test_precision_weighted', 'mean_test_recall_weighted', 'mean_test_f1_weighted']]\n",
    "cv_results.columns = [\"Criterion\", \"Max Depth\", \"Min Samples Split\", \"Min Samples Leaf\", \"C.C.I.%\", \"Precision\", \"Recall\", \"F-measure\"]\n",
    "\n",
    "\n",
    "# Find and print the best parameters\n",
    "best_params_dt = cv_results.loc[cv_results['Precision'].idxmax()]\n",
    "print(\"Best Parameters based on Precision:\")\n",
    "print(best_params_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***KNN***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters based on Precision:\n",
      "k Neighbors           15\n",
      "Weights         distance\n",
      "Metric         manhattan\n",
      "C.C.I.%         0.720455\n",
      "Precision       0.751593\n",
      "Recall          0.720455\n",
      "F-measure       0.706988\n",
      "Name: 23, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for k-NN\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 15],  # Different values of k\n",
    "    'weights': ['uniform', 'distance'],  # Weighting methods\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']  # Distance metrics\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=10, scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'], refit=False, n_jobs=-1)\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Collect all results\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results = cv_results[['param_n_neighbors', 'param_weights', 'param_metric', 'mean_test_accuracy', 'mean_test_precision_weighted', 'mean_test_recall_weighted', 'mean_test_f1_weighted']]\n",
    "cv_results.columns = [\"k Neighbors\", \"Weights\", \"Metric\", \"C.C.I.%\", \"Precision\", \"Recall\", \"F-measure\"]\n",
    "\n",
    "\n",
    "# Find and print the best parameters\n",
    "best_params_knn = cv_results.loc[cv_results['Precision'].idxmax()]\n",
    "print(\"Best Parameters based on Precision:\")\n",
    "print(best_params_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ARTIFICIAL NEURAL NETWORKS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters based on Precision:\n",
      "Hidden Layers        (10,)\n",
      "Activation        logistic\n",
      "Solver                adam\n",
      "Max Iterations        5000\n",
      "C.C.I.%           0.720455\n",
      "Precision         0.767626\n",
      "Recall            0.720455\n",
      "F-measure         0.700103\n",
      "Name: 50, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for Neural Networks (MLP)\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(10,), (20,), (10,10), (20,10)],  \n",
    "    'activation': ['relu', 'tanh', 'logistic'],  # Activation functions\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'max_iter': [2000, 5000, 10000] # Maximum iterations \n",
    "}\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=10, scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'], refit=False, n_jobs=-1)\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Collect all results\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results = cv_results[['param_hidden_layer_sizes', 'param_activation', 'param_solver', 'param_max_iter', 'mean_test_accuracy', 'mean_test_precision_weighted', 'mean_test_recall_weighted', 'mean_test_f1_weighted']]\n",
    "cv_results.columns = [\"Hidden Layers\", \"Activation\", \"Solver\", \"Max Iterations\", \"C.C.I.%\", \"Precision\", \"Recall\", \"F-measure\"]\n",
    "\n",
    "\n",
    "# Find and print the best parameters\n",
    "best_params_mlp = cv_results.loc[cv_results['Precision'].idxmax()]\n",
    "print(\"Best Parameters based on Precision:\")\n",
    "print(best_params_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mean_test_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mean_test_accuracy'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m----> 2\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mbest_params_logreg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean_test_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, best_params_logreg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_precision_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m], best_params_logreg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_recall_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m], best_params_logreg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_f1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m      3\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecision Tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params_dt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], best_params_dt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_precision_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m], best_params_dt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_recall_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m], best_params_dt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_f1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m      4\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk-NN\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params_knn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], best_params_knn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_precision_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m], best_params_knn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_recall_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m], best_params_knn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_f1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m      5\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeural Network\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params_mlp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], best_params_mlp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_precision_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m], best_params_mlp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_recall_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m], best_params_mlp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_f1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      6\u001b[0m ]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Convert results to DataFrame\u001b[39;00m\n\u001b[0;32m      9\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlgorithm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC.C.I.\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF-measure\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mean_test_accuracy'"
     ]
    }
   ],
   "source": [
    "results = [\n",
    "    [\"Logistic Regression\", best_params_logreg['mean_test_accuracy'], best_params_logreg['mean_test_precision_weighted'], best_params_logreg['mean_test_recall_weighted'], best_params_logreg['mean_test_f1_weighted']],\n",
    "    [\"Decision Tree\", best_params_dt['mean_test_accuracy'], best_params_dt['mean_test_precision_weighted'], best_params_dt['mean_test_recall_weighted'], best_params_dt['mean_test_f1_weighted']],\n",
    "    [\"k-NN\", best_params_knn['mean_test_accuracy'], best_params_knn['mean_test_precision_weighted'], best_params_knn['mean_test_recall_weighted'], best_params_knn['mean_test_f1_weighted']],\n",
    "    [\"Neural Network\", best_params_mlp['mean_test_accuracy'], best_params_mlp['mean_test_precision_weighted'], best_params_mlp['mean_test_recall_weighted'], best_params_mlp['mean_test_f1_weighted']]\n",
    "]\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results, columns=[\"Algorithm\", \"C.C.I.%\", \"Precision\", \"Recall\", \"F-measure\"])\n",
    "\n",
    "# Display the table\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
