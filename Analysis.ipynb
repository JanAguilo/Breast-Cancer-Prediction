{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>HOMA</th>\n",
       "      <th>Leptin</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>Resistin</th>\n",
       "      <th>MCP.1</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>70</td>\n",
       "      <td>2.707</td>\n",
       "      <td>0.467409</td>\n",
       "      <td>8.8071</td>\n",
       "      <td>9.702400</td>\n",
       "      <td>7.99585</td>\n",
       "      <td>417.114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>20.690495</td>\n",
       "      <td>92</td>\n",
       "      <td>3.115</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>8.8438</td>\n",
       "      <td>5.429285</td>\n",
       "      <td>4.06405</td>\n",
       "      <td>468.786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>23.124670</td>\n",
       "      <td>91</td>\n",
       "      <td>4.498</td>\n",
       "      <td>1.009651</td>\n",
       "      <td>17.9393</td>\n",
       "      <td>22.432040</td>\n",
       "      <td>9.27715</td>\n",
       "      <td>554.697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>21.367521</td>\n",
       "      <td>77</td>\n",
       "      <td>3.226</td>\n",
       "      <td>0.612725</td>\n",
       "      <td>9.8827</td>\n",
       "      <td>7.169560</td>\n",
       "      <td>12.76600</td>\n",
       "      <td>928.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>92</td>\n",
       "      <td>3.549</td>\n",
       "      <td>0.805386</td>\n",
       "      <td>6.6994</td>\n",
       "      <td>4.819240</td>\n",
       "      <td>10.57635</td>\n",
       "      <td>773.920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age        BMI  Glucose  Insulin      HOMA   Leptin  Adiponectin  Resistin  \\\n",
       "0   48  23.500000       70    2.707  0.467409   8.8071     9.702400   7.99585   \n",
       "1   83  20.690495       92    3.115  0.706897   8.8438     5.429285   4.06405   \n",
       "2   82  23.124670       91    4.498  1.009651  17.9393    22.432040   9.27715   \n",
       "3   68  21.367521       77    3.226  0.612725   9.8827     7.169560  12.76600   \n",
       "4   86  21.111111       92    3.549  0.805386   6.6994     4.819240  10.57635   \n",
       "\n",
       "     MCP.1  Classification  \n",
       "0  417.114               1  \n",
       "1  468.786               1  \n",
       "2  554.697               1  \n",
       "3  928.220               1  \n",
       "4  773.920               1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Summary:\n",
      "              Age         BMI     Glucose     Insulin        HOMA      Leptin  \\\n",
      "count  116.000000  116.000000  116.000000  116.000000  116.000000  116.000000   \n",
      "mean    57.301724   27.582111   97.793103   10.012086    2.694988   26.615080   \n",
      "std     16.112766    5.020136   22.525162   10.067768    3.642043   19.183294   \n",
      "min     24.000000   18.370000   60.000000    2.432000    0.467409    4.311000   \n",
      "25%     45.000000   22.973205   85.750000    4.359250    0.917966   12.313675   \n",
      "50%     56.000000   27.662416   92.000000    5.924500    1.380939   20.271000   \n",
      "75%     71.000000   31.241442  102.000000   11.189250    2.857787   37.378300   \n",
      "max     89.000000   38.578759  201.000000   58.460000   25.050342   90.280000   \n",
      "\n",
      "       Adiponectin    Resistin        MCP.1  Classification  \n",
      "count   116.000000  116.000000   116.000000      116.000000  \n",
      "mean     10.180874   14.725966   534.647000        1.551724  \n",
      "std       6.843341   12.390646   345.912663        0.499475  \n",
      "min       1.656020    3.210000    45.843000        1.000000  \n",
      "25%       5.474283    6.881763   269.978250        1.000000  \n",
      "50%       8.352692   10.827740   471.322500        2.000000  \n",
      "75%      11.815970   17.755207   700.085000        2.000000  \n",
      "max      38.040000   82.100000  1698.440000        2.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dataR2.csv\")\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nDataset Summary:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import RFE   \n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***NAIVE APPROACH WITH SOME PARAMETERS***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Algorithm   C.C.I.%  Precision    Recall  F-measure\n",
      "0  Baseline Classifier  0.551724   0.304400  0.551724   0.392337\n",
      "1  Logistic Regression  0.687879   0.721989  0.687879   0.665287\n",
      "2        Decision Tree  0.679545   0.698961  0.688636   0.695880\n",
      "3           k-NN (k=5)  0.650000   0.639278  0.650000   0.629348\n",
      "4       Neural Network  0.660606   0.741966  0.650758   0.666688\n"
     ]
    }
   ],
   "source": [
    "# Define features and target variable\n",
    "X = df.drop(columns=['Classification'])  # Assuming 'Classification' is the target column\n",
    "y = df['Classification']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"k-NN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Neural Network\": MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1000)\n",
    "}\n",
    "\n",
    "# Perform 10-fold cross-validation and collect results\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    accuracy = np.mean(cross_val_score(model, X_scaled, y, cv=10, scoring='accuracy'))\n",
    "    precision = np.mean(cross_val_score(model, X_scaled, y, cv=10, scoring='precision_weighted'))\n",
    "    recall = np.mean(cross_val_score(model, X_scaled, y, cv=10, scoring='recall_weighted'))\n",
    "    f1 = np.mean(cross_val_score(model, X_scaled, y, cv=10, scoring='f1_weighted'))\n",
    "    results.append([name, accuracy, precision, recall, f1])\n",
    "\n",
    "# Baseline classifier (predicts majority class always)\n",
    "majority_class = y.mode()[0]\n",
    "baseline_preds = np.full(y.shape, majority_class)\n",
    "baseline_acc = accuracy_score(y, baseline_preds)\n",
    "baseline_prec = precision_score(y, baseline_preds, average='weighted', zero_division=0)\n",
    "baseline_recall = recall_score(y, baseline_preds, average='weighted', zero_division=0)\n",
    "baseline_f1 = f1_score(y, baseline_preds, average='weighted', zero_division=0)\n",
    "results.insert(0, [\"Baseline Classifier\", baseline_acc, baseline_prec, baseline_recall, baseline_f1])\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results, columns=[\"Algorithm\", \"C.C.I.%\", \"Precision\", \"Recall\", \"F-measure\"])\n",
    "\n",
    "# Display the table\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***LOGISTIC REGRESSION***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters based on Precision:\n",
      "C                      10.0\n",
      "Solver            liblinear\n",
      "Max Iterations         5000\n",
      "C.C.I.%            0.696212\n",
      "Precision          0.724716\n",
      "Recall             0.696212\n",
      "F-measure          0.678207\n",
      "Name: 32, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for Logistic Regression\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 50, 100, 200],  # Expanded range\n",
    "    'solver': ['liblinear', 'newton-cg'],  # Additional solvers\n",
    "    'max_iter': [5000, 10000, 20000, 50000]  # Increased iterations\n",
    "}\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv=10, scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'], refit=False, n_jobs=-1)\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Collect all results\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results = cv_results[['param_C', 'param_solver', 'param_max_iter', 'mean_test_accuracy', 'mean_test_precision_weighted', 'mean_test_recall_weighted', 'mean_test_f1_weighted']]\n",
    "cv_results.columns = [\"C\", \"Solver\", \"Max Iterations\", \"C.C.I.%\", \"Precision\", \"Recall\", \"F-measure\"]\n",
    "\n",
    "\n",
    "# Find and print the best parameters\n",
    "best_params_logreg = cv_results.loc[cv_results['Precision'].idxmax()]\n",
    "print(\"Best Parameters based on Precision:\")\n",
    "print(best_params_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***DECISION TREE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters based on Precision:\n",
      "Criterion             entropy\n",
      "Max Depth                  10\n",
      "Min Samples Split          10\n",
      "Min Samples Leaf            5\n",
      "C.C.I.%              0.759848\n",
      "Precision            0.809842\n",
      "Recall               0.759848\n",
      "F-measure            0.750836\n",
      "Name: 44, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for Decision Tree\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],  # Different split criteria\n",
    "    'max_depth': [10, 20, 30, 50],  # Varying tree depths\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples needed to split a node\n",
    "    'min_samples_leaf': [1, 2, 5]  # Minimum samples needed at a leaf node\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=10, scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'], refit=False, n_jobs=-1)\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Collect all results\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results = cv_results[['param_criterion', 'param_max_depth', 'param_min_samples_split', 'param_min_samples_leaf', 'mean_test_accuracy', 'mean_test_precision_weighted', 'mean_test_recall_weighted', 'mean_test_f1_weighted']]\n",
    "cv_results.columns = [\"Criterion\", \"Max Depth\", \"Min Samples Split\", \"Min Samples Leaf\", \"C.C.I.%\", \"Precision\", \"Recall\", \"F-measure\"]\n",
    "\n",
    "\n",
    "# Find and print the best parameters\n",
    "best_params_dt = cv_results.loc[cv_results['Precision'].idxmax()]\n",
    "print(\"Best Parameters based on Precision:\")\n",
    "print(best_params_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***KNN***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters based on Precision:\n",
      "k Neighbors           15\n",
      "Weights         distance\n",
      "Metric         manhattan\n",
      "C.C.I.%         0.720455\n",
      "Precision       0.751593\n",
      "Recall          0.720455\n",
      "F-measure       0.706988\n",
      "Name: 23, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for k-NN\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 15],  # Different values of k\n",
    "    'weights': ['uniform', 'distance'],  # Weighting methods\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']  # Distance metrics\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=10, scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'], refit=False, n_jobs=-1)\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Collect all results\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results = cv_results[['param_n_neighbors', 'param_weights', 'param_metric', 'mean_test_accuracy', 'mean_test_precision_weighted', 'mean_test_recall_weighted', 'mean_test_f1_weighted']]\n",
    "cv_results.columns = [\"k Neighbors\", \"Weights\", \"Metric\", \"C.C.I.%\", \"Precision\", \"Recall\", \"F-measure\"]\n",
    "\n",
    "\n",
    "# Find and print the best parameters\n",
    "best_params_knn = cv_results.loc[cv_results['Precision'].idxmax()]\n",
    "print(\"Best Parameters based on Precision:\")\n",
    "print(best_params_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ARTIFICIAL NEURAL NETWORKS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters based on Precision:\n",
      "Hidden Layers        (10,)\n",
      "Activation        logistic\n",
      "Solver                adam\n",
      "Max Iterations        2000\n",
      "C.C.I.%           0.720455\n",
      "Precision         0.768473\n",
      "Recall            0.720455\n",
      "F-measure         0.700553\n",
      "Name: 48, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for Neural Networks (MLP)\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(10,), (20,), (10,10), (20,10)],  \n",
    "    'activation': ['relu', 'tanh', 'logistic'],  # Activation functions\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'max_iter': [2000, 5000, 10000] # Maximum iterations \n",
    "}\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=10, scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'], refit=False, n_jobs=-1)\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Collect all results\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results = cv_results[['param_hidden_layer_sizes', 'param_activation', 'param_solver', 'param_max_iter', 'mean_test_accuracy', 'mean_test_precision_weighted', 'mean_test_recall_weighted', 'mean_test_f1_weighted']]\n",
    "cv_results.columns = [\"Hidden Layers\", \"Activation\", \"Solver\", \"Max Iterations\", \"C.C.I.%\", \"Precision\", \"Recall\", \"F-measure\"]\n",
    "\n",
    "\n",
    "# Find and print the best parameters\n",
    "best_params_mlp = cv_results.loc[cv_results['Precision'].idxmax()]\n",
    "print(\"Best Parameters based on Precision:\")\n",
    "print(best_params_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***RESULTS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Algorithm   C.C.I.%  Precision    Recall  F-measure\n",
      "0  Baseline Classifier  0.551724   0.304400  0.551724   0.392337\n",
      "1  Logistic Regression  0.696212   0.724716  0.696212   0.678207\n",
      "2        Decision Tree  0.759848   0.809842  0.759848   0.750836\n",
      "3                 k-NN  0.720455   0.751593  0.720455   0.706988\n",
      "4       Neural Network  0.720455   0.768473  0.720455   0.700553\n"
     ]
    }
   ],
   "source": [
    "# Baseline Classifier (Majority Class Predictor)\n",
    "majority_class = y.mode()[0]\n",
    "baseline_preds = np.full(y.shape, majority_class)\n",
    "baseline_acc = accuracy_score(y, baseline_preds)\n",
    "baseline_prec = precision_score(y, baseline_preds, average='weighted', zero_division=0)\n",
    "baseline_recall = recall_score(y, baseline_preds, average='weighted', zero_division=0)\n",
    "baseline_f1 = f1_score(y, baseline_preds, average='weighted', zero_division=0)\n",
    "\n",
    "# Collect best results from each model\n",
    "results = [\n",
    "    [\"Baseline Classifier\", baseline_acc, baseline_prec, baseline_recall, baseline_f1],\n",
    "    [\"Logistic Regression\", best_params_logreg[\"C.C.I.%\"], best_params_logreg[\"Precision\"], best_params_logreg[\"Recall\"], best_params_logreg[\"F-measure\"]],\n",
    "    [\"Decision Tree\", best_params_dt[\"C.C.I.%\"], best_params_dt[\"Precision\"], best_params_dt[\"Recall\"], best_params_dt[\"F-measure\"]],\n",
    "    [\"k-NN\", best_params_knn[\"C.C.I.%\"], best_params_knn[\"Precision\"], best_params_knn[\"Recall\"], best_params_knn[\"F-measure\"]],\n",
    "    [\"Neural Network\", best_params_mlp[\"C.C.I.%\"], best_params_mlp[\"Precision\"], best_params_mlp[\"Recall\"], best_params_mlp[\"F-measure\"]]\n",
    "]\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results, columns=[\"Algorithm\", \"C.C.I.%\", \"Precision\", \"Recall\", \"F-measure\"])\n",
    "\n",
    "# Display the table\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***OVERFITTING***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfitting Analysis:\n",
      "             Algorithm  Train Accuracy  Test Accuracy\n",
      "0  Logistic Regression        0.760870       0.875000\n",
      "1        Decision Tree        1.000000       0.750000\n",
      "2           k-NN (k=5)        0.815217       0.833333\n",
      "3       Neural Network        1.000000       0.875000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dataR2.csv\")  # Ensure this file is in your working directory\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['Classification'])  # Assuming 'Classification' is the target column\n",
    "y = df['Classification']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into train (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"k-NN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Neural Network\": MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1000)\n",
    "}\n",
    "\n",
    "# Train models and compare train/test performance\n",
    "overfitting_results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    overfitting_results.append([name, train_acc, test_acc])\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "overfitting_df = pd.DataFrame(overfitting_results, columns=[\"Algorithm\", \"Train Accuracy\", \"Test Accuracy\"])\n",
    "\n",
    "# Print results\n",
    "print(\"Overfitting Analysis:\")\n",
    "print(overfitting_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
